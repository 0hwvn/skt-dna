from this import d
import torch
from torch import nn 
from torch.nn import functional as F

from utils import *

def make_input_n_mask_pairs(x): 
    """A fucntion to make pairs of input-mask

    # Parameters
    ____________
    x : dict 
        x['input']: input time-series
        x['mask']: indicator 
    
    # Returns
    _________
    pair : torch-Tensor 
        the shape of the tensor 'pair' is b, 2*c, n, l 
        where: 
            b= batch size of the x['input']
            c= # chennels of the x['input']
            n= # time-series of the x['input']
            l= # time-stamps of the x['input'] 
    """
    b, c, n, p =  x['input'].shape # batch_size, #channel, #time-series, #time-stamps
    pair = torch.zeros((b,2*c,n,p)).to(x['input'].device)
    pair[:, ::2, ...] = x['input'] 
    pair[:, 1::2, ...] = x['mask']
    return pair

# projection layer
class ProjectionConv1x1Layer(nn.Module): 
    """Projection layer using conv1x1
    """
    def __init__(self, in_channels, out_channels, groups, **kargs): 
        super().__init__()     
        self.projection = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, groups= groups, **kargs)
        self.in_channels, self.out_channels = in_channels, out_channels 

    def forward(self, pair): 
        """Feed forward

        pair : torch-Tensor
            generated by the function: make_input_n_mask_pairs(x)
            the shape of the tensor 'pair' is b, 2*c, n, l 
        """
        return self.projection(pair)

# temporal convolution layer
class DilatedInceptionLayer(nn.Module):
    """Dilated inception layer
    """
    def __init__(self, in_channels, out_channels, **kargs):
        super().__init__()
        self.branch1x1 = nn.Conv1d(in_channels, out_channels, kernel_size= (1,1), padding= (0, 0), dilation= 1, **kargs)
        self.branch1x3 = nn.Conv1d(in_channels, out_channels, kernel_size= (1,3), padding= (0, 1), dilation= 1, **kargs)
        self.branch1x5 = nn.Conv1d(in_channels, out_channels, kernel_size= (1,3), padding= (0, 2), dilation= 2, **kargs)
        self.branch1x7 = nn.Conv1d(in_channels, out_channels, kernel_size= (1,3), padding= (0, 3), dilation= 3, **kargs)

        self.in_channels, self.out_channels = in_channels, out_channels

    def forward(self, x): 
        b, c, n, p = x.shape
        outs = torch.zeros(b, 4*c, n, p)
        for i in range(4): 
            branch = getattr(self, f'branch1x{2*i+1}')
            outs[:, i::4, ...] = branch(x) 
            # we have c groups of receptive channels...
            # = 4 channels form one group.
        return outs

class TemporalConvolutionModule(nn.Module): 
    """TemporalConvolutionModule
    """
    def __init__(self, in_channels, out_channels, **kargs): 
        super().__init__()
        self.dil_filter = DilatedInceptionLayer(in_channels, out_channels, **kargs)
        self.dil_gate = DilatedInceptionLayer(in_channels, out_channels, **kargs) 
        
        self.in_channels, self.out_channels = in_channels, out_channels  

    def forward(self, x): 
        out_filter = torch.tanh(self.dil_filter(x))
        out_gate = torch.sigmoid(self.dil_gate(x)) 
        out = out_filter*out_gate
        return out        

# graph learning layer 
class GraphLearningLayer(nn.Module): 
    """Graph learning layer

    n_nodes: the number of nodes (node= cell)
    embedding_dim: dimension of the embedding vector
    """
    def __init__(self, n_nodes, embedding_dim, k, alpha= 3.): 
        super().__init__()
        self.emb1 = nn.Embedding(n_nodes, embedding_dim=embedding_dim)
        self.emb2 = nn.Embedding(n_nodes, embedding_dim=embedding_dim)
        self.theta1 = nn.Linear(embedding_dim, embedding_dim)
        self.theta2 = nn.Linear(embedding_dim, embedding_dim)
        self.alpha = alpha # controls saturation rate of tanh: activation function.
        self.k = k

    def forward(self, idx):
        emb1 = self.emb1(idx) 
        emb2 = self.emb2(idx) 

        emb1 = torch.tanh(self.alpha * self.theta1(emb1))
        emb2 = torch.tanh(self.alpha * self.theta2(emb2))

        adj_mat = F.relu(torch.tanh(self.alpha*(emb1@emb2.T - emb2@emb1.T))) # adjacency matrix
        mask = torch.zeros(idx.size(0), idx.size(0)).to(idx.device) 
        mask.fill_(float('0'))
        s1, t1 = (adj_mat + torch.rand_like(adj_mat)*0.01).topk(self.k, 1) # values, indices
        mask.scatter_(1, t1, s1.fill_(1))
        adj_mat = adj_mat * mask 
        return adj_mat

# graph convolution layer 


import torch
from torch import nn 
from torch.nn import functional as F

class ResidualAdd(nn.Module):
    r"""Residual connection

    # Arguments
    ____________
    fn : sub-class of nn.Module          
    
    # Returns
    _________
    returns residual connection           
    """
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, **kwargs):
        res = x
        x = self.fn(x, **kwargs)
        x += res
        return x

# projection layer
class ProjectionConv1x1Layer(nn.Module): 
    r"""Projection layer using conv1x1
    """
    def __init__(self, in_channels, out_channels, groups, **kwargs): 
        super().__init__()     
        self.projection = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, groups= groups, **kwargs)
        self.in_channels, self.out_channels = in_channels, out_channels 

    def forward(self, pair): 
        r"""Feed forward

        pair : torch-Tensor
            generated by the function: make_input_n_mask_pairs(x)
            the shape of the tensor 'pair' is b, 2*c, t, n 
        """
        return self.projection(pair)

class CausalDilatedVerticalConv1d(nn.Module): 
    r"""Causal dilated convoltion
    Causal dilated convolution is based on the work by
    \"""
    Oord, A. V. D., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). 
    Wavenet: A generative model for raw audio. 
    arXiv preprint arXiv:1609.03499.
    \"""
    This module only defers from the original work inthat 
    (1) it is a group-wise convolution 
    (2) the kernel 'moves' vertically.
    """
    def __init__(self, 
                in_channels, out_channels, 
                kernel_size,  
                groups, dilation, 
                **kwargs
                ): 
        assert kernel_size[1] == 1, "kernel[1] should have size 1."
        super().__init__()
        self.pad = (kernel_size[0] - 1) * dilation 
        self.causal_conv = nn.Conv2d(in_channels, out_channels, kernel_size, 
                                        padding= (self.pad, 0), dilation= dilation, groups= groups, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size 
        self.groups = groups 
        self.dilation = dilation

    def forward(self, x): 
        x = self.causal_conv(x) 
        x = x[..., :-self.causal_conv.padding[0], :] if self.pad > 0 else x
        return x

# temporal convolution layer
class DilatedInceptionLayer(nn.Module):
    r"""Dilated inception layer
    """
    def __init__(self, in_channels, out_channels, **kwargs):
        super().__init__()
        self.branch1x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (1,1), in_channels, 1, **kwargs)
        self.branch3x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 1, **kwargs)
        self.branch5x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 2, **kwargs)
        self.branch7x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 3, **kwargs)

        self.in_channels, self.out_channels = in_channels, out_channels

    def forward(self, x): 
        b, c, n, p = x.shape
        outs = torch.zeros(b, 4*c, n, p).to(x.device)
        for i in range(4): 
            branch = getattr(self, f'branch{2*i+1}x1')
            outs[:, i::4, ...] = branch(x) 
            # we have c groups of receptive channels...
            # = 4 channels form one group.
        return outs

class TemporalConvolutionModule(nn.Module): 
    r"""TemporalConvolutionModule
    """
    def __init__(self, in_channels, out_channels, num_heteros, **kwargs): 
        super().__init__()
        self.dil_filter = DilatedInceptionLayer(in_channels, out_channels, **kwargs)
        self.dil_gate = DilatedInceptionLayer(in_channels, out_channels, **kwargs) 
        self.conv_inter = nn.Conv2d(4*in_channels, in_channels, 1, groups= num_heteros, **kwargs)
        self.in_channels, self.out_channels = in_channels, out_channels  
        self.num_heteros = num_heteros

    def forward(self, x): 
        out_filter = torch.tanh(self.dil_filter(x))
        out_gate = torch.sigmoid(self.dil_gate(x)) 
        out = out_filter*out_gate
        return self.conv_inter(out)        
